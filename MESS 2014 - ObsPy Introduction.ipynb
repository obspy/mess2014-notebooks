{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction to ObsPy\n",
      "\n",
      "![ObsPy](https://raw.github.com/obspy/website/master/logo/obspy_logo_full_524x179px.png)\n",
      "\n",
      "Goal: Familiarize yourself with ObsPy\u2019s main object types and functions\n",
      "\n",
      "\n",
      "1. Basic Object Types\n",
      "\n",
      " - Timestamps\n",
      " - Waveform Data\n",
      " - Station Metadata\n",
      " - Event Metadata\n",
      "\n",
      "2. Retrieve Data from Data Centers\n",
      "\n",
      "3. Overview over Signal Processing Routines in ObsPy\n",
      "\n",
      "\n",
      "\n",
      "Problems? Questions?\n",
      "\n",
      " - [ObsPy Documentation](http://docs.obspy.org/) (use the search)\n",
      " - Use interactive IPython help (e.g. `>>> read?`)\n",
      " - Ask! Interrupt at any time!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Basic Object Types\n",
      "\n",
      "The core functionality of ObsPy is provided by..\n",
      "\n",
      "- ..the most important base classes..\n",
      "  * the **`UTCDateTime`** class handles time information.\n",
      "  * the **`Stream`**/**`Trace`** classes handle waveform data.\n",
      "  * the **`Catalog`**/**`Event`**/... classes handle event metadata (modelled after QuakeML).\n",
      "  * the **`Inventory`**/**`Station`**/**`Response`**/... classes handle station metadata (modelled after FDSN StationXML).\n",
      "\n",
      "\n",
      "- ..and the associated functions:\n",
      "  * The **`read()`** function. Reads all kinds of waveform file formats. Outputs a **`Stream`** object.\n",
      "  * The **`readEvents()`** function. Reads QuakeML (and MCHEDR) files. Outputs a **`Catalog`** object.\n",
      "  * The **`read_inventory()`** function. Reads FDSN StationXML files. Outputs an **`Inventory`** object.\n",
      "\n",
      "\n",
      "- the most important classes/functions can be imported from main namespace (`from obspy import ...`)\n",
      "- Unified interface and functionality for handling waveform data regardless of data source\n",
      "- **`read()`**, **`readEvents()`** and **`read_inventory()`** functions access the appropriate file-format submodule/plugin using filetype autodiscovery\n",
      "- `obspy.core.util` includes some generally useful utility classes/functions (e.g. for geodetic calculations, Flinn-Engdahl regions, ..)\n",
      "- some convenience command line scripts are also included (e.g. `obspy-plot`, `obspy-print`, `obspy-scan`, ..)\n",
      "\n",
      "### 1.1 Handling Time -- **`UTCDateTime`**\n",
      "\n",
      " - All absolute time values are consistently handled with this class\n",
      " - Based on a high precision POSIX timestamp and not the Python datetime class because precision was an issue (but easy interoperability with Python's datetime class)\n",
      " - Timezone can be specified at initialization (if necessary)\n",
      "\n",
      "#### Features of **`UTCDateTime`**\n",
      "\n",
      " - Initialization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import UTCDateTime\n",
      "print UTCDateTime(\"2011-03-11T05:46:23.2\")  # mostly time strings defined by ISO standard\n",
      "print UTCDateTime(\"2011-03-11T14:46:23.2+09:00\")  # non-UTC timezone input\n",
      "print UTCDateTime(2011, 3, 11, 5, 46, 23, 2)\n",
      "print UTCDateTime(1299822383.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "UTCDateTime?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Current time can be initialized by leaving out any arguments\n",
      "print UTCDateTime()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - Attribute access"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time = UTCDateTime(\"2011-03-11T05:46:23.200000Z\")\n",
      "print time.year\n",
      "print time.julday\n",
      "print time.timestamp\n",
      "print time.weekday\n",
      "# try time.<Tab>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - Handling time differences\n",
      "   - **`+`**/**`-`** defined to add seconds to an **`UTCDateTime`** object\n",
      "   - **`-`** defined to get time difference of two **`UTCDateTime`** objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time = UTCDateTime(\"2011-03-11T05:46:23.200000Z\")\n",
      "print time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# one hour later\n",
      "print time + 3600"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time2 = UTCDateTime(2012, 1, 1)\n",
      "print time2 - time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - Precision support"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t1 = UTCDateTime(\"2011-03-11T05:46:23.200000Z\")\n",
      "t2 = UTCDateTime(\"2011-03-11T05:46:23.200001Z\")\n",
      "t1 == t2  # default precision: microsecond"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t1 = UTCDateTime(\"2011-03-11T05:46:23.200000Z\", precision=5)\n",
      "t2 = UTCDateTime(\"2011-03-11T05:46:23.200001Z\", precision=5)\n",
      "t1 == t2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **`UTCDateTime`** - Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - Calculate the number of days passed since the Tohoku main shock (the timestamp used above)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - Make a list of 10 UTCDateTime objects, starting today at 10:00\n",
      "with a spacing of 90 minutes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Below is a list of strings with origin times of magnitude 8+ earthquakes since 2000 (fetched from IRIS). Assemble a list of interevent times in days. When this is done the code cell below can be used to display a histogram."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "times = [\"2001-06-23T20:33:09\",\n",
      "         \"2003-09-25T19:50:07\",\n",
      "         \"2004-12-23T14:59:00\",\n",
      "         \"2004-12-26T00:58:52\",\n",
      "         \"2005-03-28T16:09:35\",\n",
      "         \"2006-06-01T18:57:02\",\n",
      "         \"2006-06-05T00:50:31\",\n",
      "         \"2006-11-15T11:14:14\",\n",
      "         \"2007-01-13T04:23:23\",\n",
      "         \"2007-04-01T20:39:56\",\n",
      "         \"2007-08-15T23:40:58\",\n",
      "         \"2007-09-12T11:10:26\",\n",
      "         \"2009-09-29T17:48:11\",\n",
      "         \"2010-02-27T06:34:13\",\n",
      "         \"2011-03-11T05:46:23\",\n",
      "         \"2012-04-11T08:38:36\",\n",
      "         \"2012-04-11T10:43:10\",\n",
      "         \"2013-05-24T05:44:48\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inter_event_times = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "plt.hist(inter_event_times, bins=range(0, 1000, 100))\n",
      "plt.xlabel(\"Magnitude 8+ interevent times [days]\")\n",
      "plt.ylabel(\"count\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.2 Handling Waveform Data -- **`read/Trace/Stream`**\n",
      "- read waveform data is returned as a **`Stream`** object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import read\n",
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO.mseed\", format=\"MSEED\")\n",
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- UNIX wildcards can be used to read multiple files simultaneously\n",
      "- automatic file format detection, no need to worry about file formats\n",
      "\n",
      "  - currently supported: **mseed, sac, segy, seg2, gse1/2, seisan, sh, datamark, css, wav, y, Q**\n",
      "  - more file formats are included whenever a basic reading routine is provided (or e.g. sufficient documentation on data compression etc.)\n",
      "  - custom user-specific file formats can be added (through plugin) to filetype autodiscovery in local ObsPy installation by user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import read\n",
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_*\")\n",
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- for MiniSEED files, only reading short portions of files without all of the file getting read into memory is supported (saves time and memory when working on large collections of big files)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = UTCDateTime(\"2011-03-11T05:46:23.015400Z\")\n",
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_*\", starttime=t + 10 * 60, endtime=t + 12 * 60)\n",
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The Stream Object\n",
      "\n",
      " - A Stream object is a collection of Trace objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import read\n",
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO.mseed\")\n",
      "print type(st)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print st.traces"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print st[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- More traces can be assembled using **`+`** operator (or using the `.append()` and `.extend()` methods)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st1 = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO.mseed\")\n",
      "st2 = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO_synthetics.mseed\")\n",
      "\n",
      "st = st1 + st2\n",
      "print st\n",
      "\n",
      "st3 = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_BFO_BHE.sac\")\n",
      "\n",
      "st += st3\n",
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - convenient (and nicely readable) looping over traces"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tr in st:\n",
      "    print tr.id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - Stream is useful for applying the same processing to a larger number of different waveforms or to group Traces for processing (e.g. three components of one station in one Stream)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The Trace Object\n",
      "\n",
      "- a Trace object is a single, contiguous waveform data block (i.e. regularly spaced time series, no gaps)\n",
      "- a Trace object contains a limited amount of metadata in a dictionary-like object (as **`Trace.stats`**) that fully describes the time series by specifying..\n",
      "  * recording location/instrument (network, station, location and channel code)\n",
      "  * start time\n",
      "  * sampling rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO.mseed\")\n",
      "tr = st[0]  # get the first Trace in the Stream\n",
      "print tr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tr.stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- For custom applications it is sometimes necessary to directly manipulate the metadata of a Trace.\n",
      "- The metadata of the Trace will **stay consistent**, as all values are derived from the starttime, the data and the sampling rate and are **updated automatically**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print tr.stats.delta, \"|\", tr.stats.endtime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "tr.stats.sampling_rate = 5.0\n",
      "print tr.stats.delta, \"|\", tr.stats.endtime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print tr.stats.npts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "tr.data = tr.data[:100]\n",
      "print tr.stats.npts, \"|\", tr.stats.endtime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- convenience methods make basic manipulations simple"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tr = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO.mseed\")[0]\n",
      "tr.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tr\n",
      "tr.resample(sampling_rate=100.0)\n",
      "print tr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tr\n",
      "tr.trim(tr.stats.starttime + 12 * 60, tr.stats.starttime + 14 * 60)\n",
      "print tr\n",
      "tr.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tr.detrend(\"linear\")\n",
      "tr.taper(max_percentage=0.05, type='cosine')\n",
      "tr.filter(\"lowpass\", freq=0.1)\n",
      "tr.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try tr.<Tab> for other methods defined for Trace\n",
      "tr.detrend?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Raw data available as a [**`numpy.ndarray`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) (as **`Trace.data`**)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tr.data[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Data can be directly modified e.g. ..\n",
      "\n",
      "..by doing arithmetic operations (fast, handled in C by NumPy)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tr.data ** 2 + 0.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "..by using [**`numpy.ndarray`** builtin methods](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) (also done in C by NumPy)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tr.data.max()\n",
      "print tr.data.mean()\n",
      "print tr.data.ptp()\n",
      "# try tr.data.<Tab> for a list of numpy methods defined on ndarray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "..by using **`numpy`** functions (also done in C by NumPy)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "print np.abs(tr.data)\n",
      "# you can try np.<Tab> but there is a lot in there\n",
      "# try np.a<Tab>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "..by feeding pointers to existing C/Fortran routines from inside Python!\n",
      "\n",
      "This is done internally in several places, e.g. for cross correlations, beamforming or in third-party filetype libraries e.g. libmseed.\n",
      "\n",
      "- Trace objects can also be manually generated with data in a [**`numpy.ndarray`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import Trace\n",
      "\n",
      "x = np.random.randint(-100, 100, 500)\n",
      "tr = Trace(data=x)\n",
      "tr.stats.station = \"XYZ\"\n",
      "tr.stats.starttime = UTCDateTime()\n",
      "\n",
      "tr.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Stream objects can be assembled from manually generated Traces"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import Stream\n",
      "\n",
      "tr2 = Trace(data=np.random.randint(-300, 100, 1000))\n",
      "tr2.stats.starttime = UTCDateTime()\n",
      "tr2.stats.sampling_rate = 10.0\n",
      "st = Stream([tr, tr2])\n",
      "\n",
      "st.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Builtin methods defined on **`Stream`** / **`Trace`**\n",
      "\n",
      "- Most methods that work on a Trace object also work on a Stream object. They are simply executed for every trace. [See ObsPy documentation for an overview of available methods](http://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.html) (or try **`st.<Tab>`**).\n",
      " - **`st.filter()`** - Filter all attached traces.\n",
      " - **`st.trim()`** - Cut all traces.\n",
      " - **`st.resample()`** / **`st.decimate()`** - Change the sampling rate.\n",
      " - **`st.trigger()`** - Run triggering algorithms.\n",
      " - **`st.plot()`** / **`st.spectrogram()`** - Visualize the data.\n",
      " - **`st.attach_response()`**/**`st.remove_response()`**, **`st.simulate()`** - Instrument correction\n",
      " - **`st.merge()`**, **`st.normalize()`**, **`st.detrend()`**, **`st.taper()`**, ...\n",
      "- A **`Stream`** object can also be exported to many formats, so ObsPy can be used to convert between different file formats."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_*.sac\")\n",
      "st.write(\"/tmp/output_file.mseed\", format=\"MSEED\")\n",
      "!ls -l /tmp/output_file*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/files/Stream_Trace.svg\" width=1000px>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Trace Exercises\n",
      " - Make an **`numpy.ndarray`** with zeros and (e.g. use **`numpy.zeros()`**) and put an ideal pulse somewhere in it\n",
      " - initialize a **`Trace`** object with your data array\n",
      " - Fill in some station information (e.g. network, station, ..)\n",
      " - Print trace summary and plot the trace\n",
      " - Change the sampling rate to 20 Hz\n",
      " - Change the starttime of the trace to the start time of this session\n",
      " - Print the trace summary and plot the trace again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Use **`tr.filter(...)`** and apply a lowpass filter with a corner frequency of 1 Hertz.\n",
      "- Display the preview plot, there are a few seconds of zeros that we can cut off."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Use **`tr.trim(...)`** to remove some of the zeros at start and at the end\n",
      "- show the preview plot again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Scale up the amplitudes of the trace by a factor of 500\n",
      "- Add standard normal gaussian noise to the trace (use [**`np.random.randn()`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randn.html))\n",
      "- Display the preview plot again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Stream Exercises\n",
      "\n",
      "- Read all Tohoku example earthquake data into a stream object (\"/home/mess/Desktop/data/00\\_obspy\\_intro/waveform\\_\\*\")\n",
      "- Print the stream summary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Use **`st.select()`** to only keep traces of station BFO in the stream. Show the preview plot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- trim the data to a 10 minute time window around the first arrival (just roughly looking at the preview plot)\n",
      "- display the preview plot and spectrograms for the stream (with logarithmic frequency scale, use `wlen=50` for the spectrogram plot)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- remove the linear trend from the data, apply a tapering and a lowpass at 0.1 Hertz\n",
      "- show the preview plot again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.3 Handling Station Metadata -- **`read_inventory/Inventory/...`**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- for station metadata, the de-facto standard of the future (replacing SEED/RESP) is [FDSN StationXML](http://www.fdsn.org/xml/station/)\n",
      "- FDSN StationXML files can be read using **`read_inventory()`**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import read_inventory\n",
      "# real-world StationXML files often deviate from the official schema definition\n",
      "# therefore file-format autodiscovery sometimes fails and we have to force the file format\n",
      "inventory = read_inventory(\"/home/mess/Desktop/data/00_obspy_intro/station_PFO.xml\", format=\"STATIONXML\")\n",
      "print type(inventory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- the nested ObsPy Inventory class structure (Inventory/Station/Channel/Response/...) is closely modelled after FDSN StationXML"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print inventory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "network = inventory[0]\n",
      "print network"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station = network[0]\n",
      "print station"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "channel = station[0]\n",
      "print channel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print channel.response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- for metadata read from StationXML the response information can be attached to the waveform data using the convenience method **`Stream.attach_response()`**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import read\n",
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO.mseed\")\n",
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inv = read_inventory(\"/home/mess/Desktop/data/00_obspy_intro/station_PFO.xml\", format=\"STATIONXML\")\n",
      "st.attach_response(inv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print st[0].stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- once attached to the waveform data, the instrument response can be deconvolved from the waveform data using the convenience method **`Stream.remove_response()`**\n",
      "- evalresp is used internally to calculate the instrument response"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st.plot()\n",
      "st.remove_response()\n",
      "st.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- several options can be used to specify details of the deconvolution (water level, frequency domain prefiltering), output units (velocity/displacement/acceleration), demeaning, tapering and to specify if any response stages should be omitted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st = read(\"/home/mess/Desktop/data/00_obspy_intro/waveform_PFO.mseed\")\n",
      "st.attach_response(inv)\n",
      "st.remove_response(water_level=60, pre_filt=(0.01, 0.02, 8, 10), output=\"DISP\")\n",
      "st.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- station metadata not present in StationXML yet but in Dataless SEED or RESP files can be used for instrument correction using the `.simulate()` method of Stream/Trace in a similar fashion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/files/Inventory.svg\" width=1000px>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.4 Handling Event Metadata -- **`readEvents/Catalog/Event/...`**\n",
      "\n",
      "- for event metadata, the de-facto standard is [QuakeML (an xml document structure)](https://quake.ethz.ch/quakeml/)\n",
      "- QuakeML files can be read using **`readEvents()`**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import readEvents\n",
      "\n",
      "catalog = readEvents(\"/home/mess/Desktop/data/00_obspy_intro/event_tohoku_with_big_aftershocks.xml\")\n",
      "print catalog"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- **`readEvents()`** function returns a **`Catalog`** object, which is\n",
      "a collection of **`Event`** objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(catalog)\n",
      "print type(catalog[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "event = catalog[0]\n",
      "print event"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Event objects are again collections of other resources.\n",
      "- the nested ObsPy Event class structure (Catalog/Event/Origin/Magnitude/FocalMechanism/...) is closely modelled after QuakeML"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(event.origins)\n",
      "print type(event.origins[0])\n",
      "print event.origins[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(event.magnitudes)\n",
      "print type(event.magnitudes[0])\n",
      "print event.magnitudes[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try event.<Tab> to get an idea what \"children\" elements event has"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- The Catalog object contains some convenience methods to make\n",
      "working with events easier.\n",
      "- for example, the included events can be filtered with various keys."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "largest_magnitude_events = catalog.filter(\"magnitude >= 7.8\")\n",
      "print largest_magnitude_events"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- There is a basic preview plot using the matplotlib basemap module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "catalog.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- a (modified) Catalog can be output to file (currently there is write support for QuakeML only)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "largest_magnitude_events.write(\"/tmp/large_events.xml\", format=\"QUAKEML\")\n",
      "!ls -l /tmp/large_events.xml"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- the event type classes can be used to build up Events/Catalogs/Picks/.. from scratch in custom processing work flows and to share them with other researchers in the de facto standard format QuakeML"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy.core.event import Catalog, Event, Origin, Magnitude\n",
      "from obspy.core.util.geodetics import FlinnEngdahl\n",
      "\n",
      "cat = Catalog()\n",
      "cat.description = \"Just a fictitious toy example catalog built from scratch\"\n",
      "\n",
      "e = Event()\n",
      "e.event_type = \"not existing\"\n",
      "\n",
      "o = Origin()\n",
      "o.time = UTCDateTime(2014, 2, 23, 18, 0, 0)\n",
      "o.latitude = 47.6\n",
      "o.longitude = 12.0\n",
      "o.depth = 10000\n",
      "o.depth_type = \"operator assigned\"\n",
      "o.evaluation_mode = \"manual\"\n",
      "o.evaluation_status = \"preliminary\"\n",
      "o.region = FlinnEngdahl().get_region(o.longitude, o.latitude)\n",
      "\n",
      "m = Magnitude()\n",
      "m.mag = 7.2\n",
      "m.magnitude_type = \"Mw\"\n",
      "\n",
      "m2 = Magnitude()\n",
      "m2.mag = 7.4\n",
      "m2.magnitude_type = \"Ms\"\n",
      "\n",
      "# also included could be: custom picks, amplitude measurements, station magnitudes, focal mechanisms, moment tensors, ...\n",
      "\n",
      "# make associations, put everything together\n",
      "cat.append(e)\n",
      "e.origins = [o]\n",
      "e.magnitudes = [m, m2]\n",
      "m.origin_id = o.resource_id\n",
      "m2.origin_id = o.resource_id\n",
      "\n",
      "print cat\n",
      "cat.write(\"/tmp/my_custom_events.xml\", format=\"QUAKEML\")\n",
      "!cat /tmp/my_custom_events.xml"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/files/Event.svg\" width=1000px>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Metadata Exercise\n",
      "\n",
      "- read the QuakeML file for the Tohoku event (\"/home/mess/Desktop/data/00\\_obspy\\_intro/event\\_tohoku\\_mainshock.xml\")\n",
      "- read the station metadata for station BFO (\"/home/mess/Desktop/data/00\\_obspy\\_intro/station\\_BFO.xml\")\n",
      "- print the information on both metadata"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- calculate the theoretical arrival time for \"PP\" phase at station \"BFO\" as absolute time\n",
      "  - use function `getTraveltimes` from `obspy.taup`\n",
      "  - use helper functions `gps2DistAzimuth` and `kilometer2degrees` from `obspy.core.util.geodetics` for necessary calculations\n",
      "- print both traveltime and absolute time of the theoretical arrival of \"PP\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- read the waveform data for station BFO (\"/home/mess/Desktop/data/00\\_obspy\\_intro/waveform_BFO\\*\")\n",
      "- trim to 1 minute before and 4 minutes after the theoretical \"PP\" arrival\n",
      "- attach response information to the waveforms and remove the instrument response\n",
      "- display the preview plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- The following output is produced by the [network trigger example in the ObsPy tutorial](http://docs.obspy.org/master/tutorial/code_snippets/trigger_tutorial.html#advanced-network-coincidence-trigger-example-with-similarity-detection). Assemble a preliminary Event object for the first suspected event, make a catalog with it and save it to a local file in QuakeML format.\n",
      "  * use the network trigger time as origin time\n",
      "  * for each station that triggered, add a **`Pick`** object to **`event.picks`**\n",
      "     * station code can be set for the **`Pick`** by generating a **`WaveformStreamID`** object and attaching it as **`pick.waveform_id`**\n",
      "     * the **`WaveformStreamID`** object can be initialized using e.g. **`station_code=...`** or using **`seed_string=...`**\n",
      "- optionally do the same for the second event"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trigger_list = [{'coincidence_sum': 3.0,\n",
      "                 'duration': 1.99,\n",
      "                 'stations': ['UH3', 'UH1', 'UH2'],\n",
      "                 'time': UTCDateTime(2010, 5, 27, 16, 25, 26, 710000),\n",
      "                 'trace_ids': ['BW.UH3..SHZ', 'BW.UH1..SHZ', 'BW.UH2..SHZ']},\n",
      "                {'coincidence_sum': 4.0,\n",
      "                 'duration': 4.11,\n",
      "                 'stations': ['UH3', 'UH2', 'UH1', 'UH4'],\n",
      "                 'time': UTCDateTime(2010, 5, 27, 16, 24, 33, 210000),\n",
      "                 'trace_ids': ['BW.UH3..SHZ', 'BW.UH2..SHZ', 'BW.UH1..SHZ', 'BW.UH4..SHZ']}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Retrieving Data from Data Centers / Databases\n",
      "\n",
      "ObsPy has clients to directly fetch data via..\n",
      "\n",
      "- FDSN webservices (IRIS, Geofon/GFZ, USGS, NCEDC, ...)\n",
      "- ArcLink (EIDA, ...)\n",
      "- Earthworm\n",
      "- SeedLink (near-realtime servers)\n",
      "- NERIES/NERA/seismicportal.eu\n",
      "- NEIC\n",
      "- SeisHub (local seismological database)\n",
      "\n",
      "This introduction shows how to use the FDSN webservice client. The FDSN webservice definition is the on-the-rise standard for webservices that gets implemented in many data centers at the moment. Clients for other protocols work similar to the FDSN client.\n",
      "\n",
      "#### Waveform Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy import UTCDateTime\n",
      "from obspy.fdsn import Client\n",
      "\n",
      "client = Client(\"IRIS\")\n",
      "t = UTCDateTime(\"2011-03-11T05:46:23\")  # Tohoku\n",
      "st = client.get_waveforms(\"II\", \"PFO\", \"*\", \"LHZ\", t + 10 * 60, t + 30 * 60)\n",
      "print st\n",
      "st.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- again, waveform data is returned as Stream object\n",
      "- For all custom processing workflows it does not matter if the data originates from a local file or from a webservice\n",
      "\n",
      "#### Event Metadata\n",
      "\n",
      "The FDSN client can also be used to request event metadata:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = UTCDateTime(\"2011-03-11T05:46:23\")  # Tohoku\n",
      "catalog = client.get_events(starttime=t-100, endtime=t+24*3600, minmagnitude=7)\n",
      "print catalog\n",
      "catalog.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Requests can have a wide range of constraints (see [ObsPy Documentation](http://docs.obspy.org/packages/autogen/obspy.fdsn.client.Client.get_events.html)):\n",
      "\n",
      "- time range\n",
      "- geographical (lonlat-box, circular by distance)\n",
      "- depth range\n",
      "- magnitude range, type\n",
      "- contributing agency"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Station Metadata\n",
      "\n",
      "Finally, the FDSN client can be used to request station metadata. Stations can be looked up using a wide range of constraints (see [ObsPy documentation](http://docs.obspy.org/packages/autogen/obspy.fdsn.client.Client.get_stations.html)):\n",
      "\n",
      " * network/station code\n",
      " * time range of operation\n",
      " * geographical (lonlat-box, circular by distance)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "event = catalog[0]\n",
      "origin = event.origins[0]\n",
      "\n",
      "# Bayrischzell\n",
      "lon =  12.016667\n",
      "lat =  47.666667\n",
      "\n",
      "inventory = client.get_stations(longitude=lon, latitude=lat, maxradius=1.5, level=\"station\")\n",
      "print inventory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The **`level=...`** keyword is used to specify the level of detail should in the requested inventory\n",
      "\n",
      "- `\"network\"`: only return information on networks matching the criteria\n",
      "- `\"station\"`: return information on all matching stations\n",
      "- `\"channel\"`: return information on available channels in all stations networks matching the criteria\n",
      "- `\"response\"`: include instrument response for all matching channels (large result data size!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inventory = client.get_stations(network=\"OE\", station=\"DAVA\", level=\"station\")\n",
      "print inventory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inventory = client.get_stations(network=\"OE\", station=\"DAVA\", level=\"channel\")\n",
      "print inventory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For waveform requests that include instrument correction, the appropriate instrument response information can be attached to waveforms automatically:     \n",
      "(Of course, for work on large datasets, the better choice is to download all station information and avoid the internal repeated webservice requests)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = UTCDateTime(\"2011-03-11T05:46:23\")  # Tohoku\n",
      "st = client.get_waveforms(\"II\", \"PFO\", \"*\", \"LHZ\", t + 10 * 60, t + 30 * 60, attach_response=True)\n",
      "st.plot()\n",
      "\n",
      "st.remove_response()\n",
      "st.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All data requested using the FDSN client can be directly saved to file using the **`filename=\"...\"`** option. The data is then stored exactly as it is served by the data center, i.e. without first parsing by ObsPy and outputting by ObsPy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "client.get_events(starttime=t-100, endtime=t+24*3600, minmagnitude=7, filename=\"/tmp/requested_events.xml\")\n",
      "client.get_stations(network=\"OE\", station=\"DAVA\", level=\"station\", filename=\"/tmp/requested_stations.xml\")\n",
      "client.get_waveforms(\"II\", \"PFO\", \"*\", \"LHZ\", t + 10 * 60, t + 30 * 60, filename=\"/tmp/requested_waveforms.mseed\")\n",
      "!ls -lrt /tmp/requested*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### FDSN Client Exercise\n",
      "\n",
      "Use the FDSN client to assemble a waveform dataset for on Event.\n",
      "\n",
      "- search for a large earthquake (e.g. by depth or in a region of your choice, use option **`limit=5`** to keep network traffic down)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- search for stations to look at waveforms for the event. stations should..\n",
      "    * be available at the time of the event\n",
      "    * have a vertical 1 Hz stream (\"LHZ\", to not overpower our network..)\n",
      "    * be in a narrow angular distance around the event (e.g. 90-91 degrees)\n",
      "    * adjust your search so that only a small number of stations (e.g. 3-6) match your search criteria"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- for each of these stations download data of the event (e.g. some minutes roughly starting at \"P\" or \"Pdiff\"\n",
      "- use the taup call below for a traveltime plot to get a rough estimate of the expected traveltime\n",
      "- put all data together in one stream (put the `get_waveforms()` call in a try/except/pass block to silently skip stations that actually have no data available)\n",
      "- print stream info, plot the raw data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from obspy.taup import travelTimePlot\n",
      "travelTimePlot(phases=[\"P\", \"Pdiff\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- attach the station metadata to the waveforms (if not done during fetching the waveforms already)\n",
      "- correct the instrument response for all stations and plot the corrected data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you have time, assemble and plot another similar dataset (e.g. like before stations at a certain distance from a big event, or use Transportable Array data for a big event, etc.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. obspy.signal - Builtin Signal Processing Routines\n",
      "\n",
      "- the most important functionality (filter, instrument correction) is available as convenience methods attached to Trace/Stream\n",
      "   - makes life easier, code shorter and better readable\n",
      "   - less error prone (e.g. correct sampling rate is automatically filled in, ...)\n",
      "- contributions of processing routines that might be interesting for the community are highly welcome!\n",
      "- a variety of signal processing routines is available in [obspy.signal](http://docs.obspy.org/packages/obspy.signal.html) (all plots taken from the [ObsPy Documentation](http://docs.obspy.org) / [ObsPy Tutorial](http://docs.obspy.org/tutorial/index.html) / [ObsPy Gallery](http://docs.obspy.org/gallery.html)):\n",
      "  - filters (mostly butterworth, using [scipy](http://www.scipy.org/))\n",
      "  - instrument correction / simulation\n",
      "     - using poles and zeros and overall sensitivity\n",
      "     - calculated from all/selected response stages using evalresp\n",
      "  - local magnitude estimation\n",
      "  - spectral estimation\n",
      "     - psd\n",
      "     - spectrogram\n",
      "     - probabilistic power spectral density\n",
      "     - konno-ohmachi-smoothing       \n",
      "<img src=\"files/files/spectrogram.png\" width=500px>\n",
      "<img src=\"files/files/ppsd.png\" width=600px>\n",
      "  - cross correlations\n",
      "     - pick correction\n",
      "     - similarity analysis      \n",
      "<img src=\"files/files/pick_correction.png\" width=600px>\n",
      "  - triggering\n",
      "     - classic/delayed/recursive STA/LTA\n",
      "     - z-Detector\n",
      "     - Baer picker\n",
      "     - AR picker\n",
      "     - network coincidence triggering routines (including optional single station cross correlation similarity detection)      \n",
      "<img src=\"files/files/trigger.png\" width=600px>\n",
      "  - relative instrument calibration\n",
      "  - array analysis (currently being extended for this course)\n",
      "     - beamforming\n",
      "     - FK analysis\n",
      "     - array transfer function\n",
      "     - array derived rotation      \n",
      "<img src=\"files/files/fk.png\" width=500px>\n",
      "<img src=\"files/files/fk2.png\" width=500px>\n",
      "<img src=\"files/files/array_response.png\" width=500px>\n",
      "  - time-frequency misfit calculations     \n",
      "<img src=\"files/files/tf_misfit.png\" width=600px>\n",
      "  - rotations ZRT, LQT\n",
      "  - complex trace analysis / frequency attributes / half octave bands / polarization analysis"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}